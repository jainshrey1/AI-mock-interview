TrainingArguments:
  output_dir: ./output
  num_train_epochs: 1
  max_steps: 50
  learning_rate: 0.0002
  optim: paged_adamw_8bit
  warmup_steps: 1
  per_device_train_batch_size: 1
  weight_decay: 0.01
  logging_steps: 25
  logging_dir: ./logs
  save_strategy: steps
  save_steps: 25
  evaluation_strategy: steps
  eval_steps: 25
  do_eval: True
  report_to: none
  overwrite_output_dir: True
  group_by_length: True
  gradient_checkpointing: True
  gradient_accumulation_steps: 4